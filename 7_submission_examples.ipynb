{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this notebook is to show submission examples for different configurations mentioned in the previous notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General submission process\n",
    "\n",
    "All submissions are processed by the codabench plateform. In order to submit a model for the competition, the submission folder need to be compressed as a zip file (be carefull to compress all the files and not the folder itself, the unzipping need to recreate the file and not a folder containing the files). This zip can then be uploaded on the `my_submission` tab :\n",
    "\n",
    "![Alt text](img/Submission_New.png)\n",
    "\n",
    "Once submitted it is processed by the codabench plateform and send to one of our compute node for evaluation. It is possible to see the current status of the submission (submitted, waiting for worker, running, done) however the logs will only be available once the submission is running. \n",
    "\n",
    "Please note that we currently have a 12hours limit for the execution of a submission (training, evaluation and scoring)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1 : simple submission\n",
    "\n",
    "This example is available in submission/simple, a torch and tensorflow variations are provided.\n",
    "\n",
    "It corresponds to a simple submission that use pre-implemented model and scaler and allows to submit the 1st example from the 4th notebook.\n",
    "This submission is composed of 3 files :\n",
    "- parameters.json\n",
    "- config.ini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parameters.json\n",
    "\n",
    "In this example we are using a fully connected model implemented through torch and already available in the LIPS package :\n",
    "- `from lips.augmented_simulators.torch_models.fully_connected import TorchFullyConnected`\n",
    "\n",
    "We also want to train and evaluate the model. As such we indicate \n",
    "- `evaluateonly: false`\n",
    "- `scoringonly\": false`\n",
    "\n",
    "#### simulator_config :\n",
    "As we are using an already implemented simulator/model, we should indicate:\n",
    "- `simulator_type : simple_torch` \n",
    "Which indicate to the compute node that it will need to load the model from the LIPS package\n",
    "\n",
    "We name the model (used for saving and retrieving models, not important in this type of submission):\n",
    "- `name: \"MyAugmentedSimulator\"`\n",
    "\n",
    "And indicates to the compute node which module (`model_type`) and class (`model`) we are using :\n",
    "- `model_type: \"fully_connected\"`\n",
    "- `model: \"TorchFullyConnected\"`\n",
    "\n",
    "This will load the following model when running :  `from lips.augmented_simulators.torch_models.fully_connected import TorchFullyConnected`\n",
    "\n",
    "In this example we also use a pre-implemented scaler : `from lips.dataset.scaler.standard_scaler import StandardScaler`\n",
    "Similarly we indicate which scaler module and class to load :\n",
    "- `scaler_type: \"simple\"`\n",
    "- `scaler_module: \"standard_scaler\"`\n",
    "- `scaler: \"StandardScaler\"`\n",
    "\n",
    "We then indicate which configuration will need to be used from the config.ini file (in this example we use the standard config presented in the 1st example of notebook 4):\n",
    "- `config_name: \"DEFAULT\"`\n",
    "\n",
    "#### simulator_extra_parameters:\n",
    "This section is used to pass custom parameters to the model and generally will be only used in association with a custom model as presented in the following example.\n",
    "As we are running a pre-implemented model, we do not pass any custom parameters and `simulator_extra_parameters` stay empty :\n",
    "- `simulator_extra_parameters: {}`\n",
    "\n",
    "#### training_config:\n",
    "We now configure to run the training for 10 epochs :\n",
    "- `training_config: {\"epoch\": 10}`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting `parameters.json` file :\n",
    "```json\n",
    "{\n",
    "  \"evaluateonly\": false,\n",
    "  \"scoringonly\": false,\n",
    "  \"simulator_config\": {\n",
    "    \"simulator_type\": \"simple_torch\",\n",
    "    \"name\": \"MyAugmentedSimulator\",\n",
    "    \"model_type\": \"fully_connected\",\n",
    "    \"model\": \"TorchFullyConnected\",\n",
    "    \"scaler_type\": \"simple\",\n",
    "    \"scaler_module\": \"standard_scaler\",\n",
    "    \"scaler\": \"StandardScaler\",\n",
    "    \"config_name\": \"DEFAULT\",\n",
    "  },\n",
    "  \"simulator_extra_parameters\": {},\n",
    "  \"training_config\": {\n",
    "    \"epochs\": 10\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### config.ini\n",
    "This file is used to pass the configuration used in the model, as presented in notebook 4.\n",
    "We had the configuration file as defined in previous notebook :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```json\n",
    "[DEFAULT]\n",
    "name = \"torch_fc\"\n",
    "layers = (300, 300, 300, 300)\n",
    "activation = \"relu\"\n",
    "layer = \"linear\"\n",
    "input_dropout = 0.0\n",
    "dropout = 0.0\n",
    "metrics = (\"MAELoss\",)\n",
    "loss = {\"name\": \"MSELoss\",\n",
    "        \"params\": {\"size_average\": None,\n",
    "                   \"reduce\": None,\n",
    "                   \"reduction\": 'mean'}}\n",
    "device = \"cpu\"\n",
    "optimizer = {\"name\": \"adam\",\n",
    "             \"params\": {\"lr\": 3e-4}}\n",
    "train_batch_size = 128\n",
    "eval_batch_size = 128\n",
    "epochs = 10\n",
    "shuffle = False\n",
    "save_freq = False\n",
    "ckpt_freq = 50\n",
    "\n",
    "benchmark_kwargs = {\"attr_x\": (\"prod_p\", \"prod_v\", \"load_p\", \"load_q\"),\n",
    "                    \"attr_y\": (\"a_or\", \"a_ex\", \"p_or\", \"p_ex\", \"v_or\", \"v_ex\"),\n",
    "                    \"attr_tau\": (\"line_status\", \"topo_vect\"),\n",
    "                    \"attr_physics\": None}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">The `config.ini` file should contain the `benchmark_kwargs` key which will be used to consider the required set of variables.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2 : intermediate torch model using LIPS simulator class\n",
    "\n",
    "This example is available in `submission/intermediate_torch`\n",
    "\n",
    "It corresponds to a submission that use a custom model implemented in `MyCustomFullyConnected.py` and a pre-implemented scaler. It corresponds to the 2nd example from the 4th notebook.\n",
    "\n",
    "This submission is composed of 3 files :\n",
    "- parameters.json\n",
    "- config.ini\n",
    "- MyCustomFullyConnected.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parameters.json\n",
    "\n",
    "\n",
    "In this example we are using a custom model implemented in `my_augmented_simulator.py`\n",
    "\n",
    "We also want to train and evaluate the model as such we indicate \n",
    "- `evaluateonly: false`\n",
    "- `scoringonly\": false`\n",
    "\n",
    "#### simulator_config :\n",
    "As we are use a custom torch simulator we use :\n",
    "- `simulator_type : \"intermediate_torch\"`\n",
    "- `simulator_file : \"my_augmented_simulator\"`\n",
    "Which indicate to the compute node that it will need to load the model from `MyCustomFullyConnected.py`\n",
    "\n",
    "We name the model (used for saving an retrieving models, not important in this type of submission):\n",
    "- `name: \"MyAugmentedSimulator\"`\n",
    "And indicates to the compute node which model we are using :\n",
    "- `model: \"MyCustomFullyConnected\"`\n",
    "This correspond to the name of the class implemented in `MyCustomFullyConnected.py`.\n",
    "\n",
    "In this example we also use a pre-implemented scaler : `from lips.dataset.scaler.standard_scaler import StandardScaler`\n",
    "Similarly we indicate which scaler class and implementation to load :\n",
    "- `scaler_type: \"simple\"`\n",
    "- `scaler_module: \"standard_scaler\"`\n",
    "- `scaler: \"StandardScaler\"`\n",
    "\n",
    "We then indicate which configuration will need to be used from the config.ini file (in this example we use the standard config presented in the 1st example of notebook 4):\n",
    "- `config_name: \"DEFAULT\"`\n",
    "\n",
    "#### simulator_extra_parameters:\n",
    "This section is used to pass custom parameters to the model, it presents in the same form as training_config.\n",
    "In this case, we do not pass any custom parameters and `simulator_extra_parameters` stay empty :\n",
    "- `simulator_extra_parameters: {}`\n",
    "\n",
    "#### training_config:\n",
    "We now configure to run the training for 10 epochs :\n",
    "- `training_config: {\"epoch\": 10}`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting `parameters.json` file :\n",
    "```json\n",
    "{\n",
    "  \"evaluateonly\": false,\n",
    "  \"scoringonly\": false,\n",
    "  \"simulator_config\": {\n",
    "    \"simulator_type\": \"intermediate_torch\",\n",
    "    \"simulator_file\": \"MyCustomFullyConnected\",\n",
    "    \"name\": \"custom_name\",    \n",
    "    \"model\": \"MyCustomFullyConnected\",\n",
    "    \"scaler_type\": \"simple\",\n",
    "    \"scaler_module\": \"standard_scaler\",\n",
    "    \"scaler\": \"StandardScaler\",\n",
    "    \"config_name\": \"DEFAULT\",\n",
    "  },\n",
    "  \"simulator_extra_parameters\": {},\n",
    "  \"training_config\": {\n",
    "    \"epochs\": 10\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### config.ini\n",
    "This file is used to pass the configuration used in the model, as presented in notebook 4.\n",
    "We had the configuration file as defined in previous notebook :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```json\n",
    "[DEFAULT]\n",
    "name = \"torch_fc\"\n",
    "layers = (300, 300, 300, 300)\n",
    "activation = \"relu\"\n",
    "layer = \"linear\"\n",
    "input_dropout = 0.0\n",
    "dropout = 0.0\n",
    "metrics = (\"MAELoss\",)\n",
    "loss = {\"name\": \"MSELoss\",\n",
    "        \"params\": {\"size_average\": None,\n",
    "                   \"reduce\": None,\n",
    "                   \"reduction\": 'mean'}}\n",
    "device = \"cpu\"\n",
    "optimizer = {\"name\": \"adam\",\n",
    "             \"params\": {\"lr\": 3e-4}}\n",
    "train_batch_size = 128\n",
    "eval_batch_size = 128\n",
    "epochs = 10\n",
    "shuffle = False\n",
    "save_freq = False\n",
    "ckpt_freq = 50\n",
    "\n",
    "benchmark_kwargs = {\"attr_x\": (\"prod_p\", \"prod_v\", \"load_p\", \"load_q\"),\n",
    "                    \"attr_y\": (\"a_or\", \"a_ex\", \"p_or\", \"p_ex\", \"v_or\", \"v_ex\"),\n",
    "                    \"attr_tau\": (\"line_status\", \"topo_vect\"),\n",
    "                    \"attr_physics\": None}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### my_augmented_simulator.py\n",
    "\n",
    "This file contains the implementation of a custom model. This implementation needs to be compatible with the LIPS simulator class in order for the simulation and evaluation processes to be able to access it. Here we implement and example of a fully connected pytorch model as seen in the 2nd example of the 4th notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Torch fully connected model\n",
    "\"\"\"\n",
    "import os\n",
    "import pathlib\n",
    "from typing import Union\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from lips.dataset import DataSet\n",
    "from lips.dataset.scaler import Scaler\n",
    "from lips.logger import CustomLogger\n",
    "from lips.config import ConfigManager\n",
    "from lips.utils import NpEncoder\n",
    "from lips.augmented_simulators.torch_models.utils import LOSSES\n",
    "\n",
    "class MyCustomFullyConnected(nn.Module):\n",
    "    def __init__(self,\n",
    "                 sim_config_path: Union[pathlib.Path, str],\n",
    "                 bench_config_path: Union[str, pathlib.Path],\n",
    "                 sim_config_name: Union[str, None]=None,\n",
    "                 bench_config_name: Union[str, None]=None,\n",
    "                 bench_kwargs: dict={},\n",
    "                 name: Union[str, None]=None,\n",
    "                 scaler: Union[Scaler, None]=None,\n",
    "                 log_path: Union[None, pathlib.Path, str]=None,\n",
    "                 **kwargs):\n",
    "        super().__init__()\n",
    "        if not os.path.exists(sim_config_path):\n",
    "            raise RuntimeError(\"Configuration path for the simulator not found!\")\n",
    "        if not str(sim_config_path).endswith(\".ini\"):\n",
    "            raise RuntimeError(\"The configuration file should have `.ini` extension!\")\n",
    "        sim_config_name = sim_config_name if sim_config_name is not None else \"DEFAULT\"\n",
    "        self.sim_config = ConfigManager(section_name=sim_config_name, path=sim_config_path)\n",
    "        self.bench_config = ConfigManager(section_name=bench_config_name, path=bench_config_path)\n",
    "        self.bench_config.set_options_from_dict(**bench_kwargs)\n",
    "        self.name = name if name is not None else self.sim_config.get_option(\"name\")\n",
    "        # scaler\n",
    "        self.scaler = scaler\n",
    "        # Logger\n",
    "        self.log_path = log_path\n",
    "        self.logger = CustomLogger(__class__.__name__, log_path).logger\n",
    "        # model parameters\n",
    "        self.params = self.sim_config.get_options_dict()\n",
    "        self.params.update(kwargs)\n",
    "\n",
    "        self.activation = {\n",
    "            \"relu\": F.relu,\n",
    "            \"sigmoid\": F.sigmoid,\n",
    "            \"tanh\": F.tanh\n",
    "        }\n",
    "\n",
    "        self.input_size = None if kwargs.get(\"input_size\") is None else kwargs[\"input_size\"]\n",
    "        self.output_size = None if kwargs.get(\"output_size\") is None else kwargs[\"output_size\"]\n",
    "\n",
    "        self.input_layer = None\n",
    "        self.input_dropout = None\n",
    "        self.fc_layers = None\n",
    "        self.dropout_layers = None\n",
    "        self.output_layer = None\n",
    "\n",
    "        self._data = None\n",
    "        self._target = None\n",
    "\n",
    "    def build_model(self):\n",
    "        \"\"\"Build the model architecture\n",
    "        \"\"\"\n",
    "        linear_sizes = list(self.params[\"layers\"])\n",
    "\n",
    "        self.input_layer = nn.Linear(self.input_size, linear_sizes[0])\n",
    "        self.input_dropout = nn.Dropout(p=self.params[\"input_dropout\"])\n",
    "\n",
    "        self.fc_layers = nn.ModuleList([nn.Linear(in_f, out_f) \\\n",
    "            for in_f, out_f in zip(linear_sizes[:-1], linear_sizes[1:])])\n",
    "\n",
    "        self.dropout_layers = nn.ModuleList([nn.Dropout(p=self.params[\"dropout\"]) \\\n",
    "            for _ in range(len(self.fc_layers))])\n",
    "\n",
    "        self.output_layer = nn.Linear(linear_sizes[-1], self.output_size)\n",
    "\n",
    "    def forward(self, data):\n",
    "        \"\"\"The forward pass of the model\n",
    "        \"\"\"\n",
    "        out = self.input_layer(data)\n",
    "        out = self.input_dropout(out)\n",
    "        for _, (fc_, dropout) in enumerate(zip(self.fc_layers, self.dropout_layers)):\n",
    "            out = fc_(out)\n",
    "            out = self.activation[self.params[\"activation\"]](out)\n",
    "            out = dropout(out)\n",
    "        out = self.output_layer(out)\n",
    "        return out\n",
    "\n",
    "    def process_dataset(self, dataset: DataSet, training: bool, **kwargs):\n",
    "        \"\"\"process the datasets for training and evaluation\n",
    "\n",
    "        This function transforms all the dataset into something that can be used by the neural network (for example)\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        dataset : DataSet\n",
    "            A dataset that should be processed\n",
    "        training : bool, optional\n",
    "            indicate if we are in training phase or not, by default False\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        DataLoader\n",
    "            _description_\n",
    "        \"\"\"\n",
    "        dtype = kwargs.get(\"dtype\", torch.float32)\n",
    "        if training:\n",
    "            self._infer_size(dataset)\n",
    "            batch_size = self.params[\"train_batch_size\"]\n",
    "            extract_x, extract_y = dataset.extract_data()\n",
    "            if self.scaler is not None:\n",
    "                extract_x, extract_y = self.scaler.fit_transform(extract_x, extract_y)\n",
    "        else:\n",
    "            batch_size = self.params[\"eval_batch_size\"]\n",
    "            extract_x, extract_y = dataset.extract_data()\n",
    "            if self.scaler is not None:\n",
    "                extract_x, extract_y = self.scaler.transform(extract_x, extract_y)\n",
    "\n",
    "        torch_dataset = TensorDataset(torch.tensor(extract_x, dtype=dtype), torch.tensor(extract_y, dtype=dtype))\n",
    "        data_loader = DataLoader(torch_dataset, batch_size=batch_size, shuffle=self.params[\"shuffle\"])\n",
    "        return data_loader\n",
    "\n",
    "    def _post_process(self, data):\n",
    "        \"\"\"\n",
    "        This function is used to inverse the predictions of the model to their original state, before scaling\n",
    "        to be able to compare them with ground truth data\n",
    "        \"\"\"\n",
    "        if self.scaler is not None:\n",
    "            try:\n",
    "                processed = self.scaler.inverse_transform(data)\n",
    "            except TypeError:\n",
    "                processed = self.scaler.inverse_transform(data.cpu())\n",
    "        else:\n",
    "            processed = data\n",
    "        return processed\n",
    "\n",
    "    def _reconstruct_output(self, dataset: DataSet, data: npt.NDArray[np.float64]) -> dict:\n",
    "        \"\"\"Reconstruct the outputs to obtain the desired shape for evaluation\n",
    "\n",
    "        In the simplest form, this function is implemented in DataSet class. It supposes that the predictions \n",
    "        obtained by the augmented simulator are exactly the same as the one indicated in the configuration file\n",
    "\n",
    "        However, if some transformations required by each specific model, the extra operations to obtained the\n",
    "        desired output shape should be done in this function.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        dataset : DataSet\n",
    "            An object of the `DataSet` class \n",
    "        data : npt.NDArray[np.float64]\n",
    "            the data which should be reconstructed to the desired form\n",
    "        \"\"\"\n",
    "        data_rec = dataset.reconstruct_output(data)\n",
    "        return data_rec\n",
    "    \n",
    "    def _infer_size(self, dataset: DataSet):\n",
    "        \"\"\"Infer the size of the input and ouput variables\n",
    "        \"\"\"\n",
    "        *dim_inputs, self.output_size = dataset.get_sizes()\n",
    "        self.input_size = np.sum(dim_inputs)\n",
    "\n",
    "    def get_metadata(self):\n",
    "        res_json = {}\n",
    "        res_json[\"input_size\"] = self.input_size\n",
    "        res_json[\"output_size\"] = self.output_size\n",
    "        return res_json\n",
    "\n",
    "    def _save_metadata(self, path: str):\n",
    "        res_json = {}\n",
    "        res_json[\"input_size\"] = self.input_size\n",
    "        res_json[\"output_size\"] = self.output_size\n",
    "        with open((path / \"metadata.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(obj=res_json, fp=f, indent=4, sort_keys=True, cls=NpEncoder)\n",
    "\n",
    "    def _load_metadata(self, path: str):\n",
    "        if not isinstance(path, pathlib.Path):\n",
    "            path = pathlib.Path(path)\n",
    "        with open((path / \"metadata.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "            res_json = json.load(fp=f)\n",
    "        self.input_size = res_json[\"input_size\"]\n",
    "        self.output_size = res_json[\"output_size\"]\n",
    "\n",
    "    def _do_forward(self, batch, **kwargs):\n",
    "        \"\"\"Do the forward step through a batch of data\n",
    "\n",
    "        This step could be very specific to each augmented simulator as each architecture\n",
    "        takes various inputs during the learning procedure. \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        batch : _type_\n",
    "            A batch of data including various information required by an architecture\n",
    "        device : _type_\n",
    "            the device on which the data should be processed\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        ``tuple``\n",
    "            returns the predictions made by the augmented simulator and also the real targets\n",
    "            on which the loss function should be computed\n",
    "        \"\"\"\n",
    "        non_blocking = kwargs.get(\"non_blocking\", True)\n",
    "        device = self.params.get(\"device\", \"cpu\")\n",
    "        self._data, self._target = batch\n",
    "        self._data = self._data.to(device, non_blocking=non_blocking)\n",
    "        self._target = self._target.to(device, non_blocking=non_blocking)\n",
    "\n",
    "        predictions = self.forward(self._data)\n",
    "        \n",
    "        return self._data, predictions, self._target\n",
    "\n",
    "    def get_loss_func(self, loss_name: str, **kwargs) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Helper to get loss. It is specific to each architecture\n",
    "        \"\"\"\n",
    "        loss_func = LOSSES[loss_name](**kwargs)\n",
    "        \n",
    "        return loss_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3 : Advanced model independent from the LIPS framework\n",
    "\n",
    "This example is available in `submission_examples/advanced_torch`\n",
    "\n",
    "It correspond to a submission that use a custom model implemented in `MyCustomFullyConnected.py`. It corresponds to the 3rd example of notebook 4a.\n",
    "\n",
    "This submission is composed of 3 files  :\n",
    "- parameters.json\n",
    "- config.ini\n",
    "- MyCustomFullyConnected.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parameters.json\n",
    "In this example we are using a custom model implemented in `MyCustomFullyConnected.py`\n",
    "\n",
    "We also want to train and evaluate the model as such we indicate \n",
    "- `evaluateonly: false`\n",
    "- `scoringonly\": false`\n",
    "\n",
    "#### simulator_config :\n",
    "As we are use a custom simulator we use :\n",
    "- `simulator_type : \"advanced\"`\n",
    "- `simulator_file : \"MyCustomFullyConnected\"`\n",
    "Which indicate to the compute node that it will need to load the model from `MyCustomFullyConnected.py`\n",
    "\n",
    "We name the model (used for saving an retrieving models, not important in this type of submission):\n",
    "- `name: \"MyAugmentedSimulator\"`\n",
    "And indicates to the compute node which model we are using :\n",
    "- `model: \"MyCustomFullyConnected\"`\n",
    "This correspond to the name of the class implemented in `MyCustomFullyConnected.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting `parameters.json` file :\n",
    "```json  \n",
    "{\n",
    "    \"evaluateonly\": false,\n",
    "    \"scoringonly\": false,\n",
    "    \"simulator_config\": {\n",
    "      \"simulator_type\": \"advanced\",\n",
    "      \"simulator_file\": \"CustomFullyConnected\",\n",
    "      \"name\": \"torch_fc\",\n",
    "      \"model\": \"TorchSimulator\",\n",
    "      \"scaler_type\": \"simple\",\n",
    "      \"scaler_module\": \"scaler\",\n",
    "      \"scaler\": \"StandardScaler\",\n",
    "      \"config_name\": \"DEFAULT\",\n",
    "      \"seed\": 42\n",
    "    },\n",
    "    \"simulator_extra_parameters\": {},\n",
    "    \"training_config\": {\n",
    "      \"epochs\": 2,\n",
    "      \"train_batch_size\": 128,\n",
    "      \"lr\": 3e-4\n",
    "    }\n",
    "  }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### my_augmented_simulator.py\n",
    "\n",
    "This file contains the implementation of a custom model. The corresponding class need to be runnable by the ingestion process and as such needs the following functions :\n",
    "- __init__(self,benchmark,**kwargs)\n",
    "- train(self,train_dataset, save_path=None)\n",
    "- predict(self,dataset,**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from lips.augmented_simulators import AugmentedSimulator\n",
    "from lips.benchmark.powergridBenchmark import PowerGridBenchmark\n",
    "\n",
    "class TorchSimulator(AugmentedSimulator):\n",
    "    \"\"\"Simulator class that allows to train and evalute your custom model\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        benchmark : PowerGridBenchmark\n",
    "            A benchmark object passed inside the ingestion program\n",
    "        config : ConfigManager\n",
    "            A lips ConfigManager object allowing the access to all the parameters in `config.ini`\n",
    "        device : torch.device\n",
    "            the device on which the execution should be executed, controlled by ingestion program\n",
    "        **kwargs\n",
    "            The set of supplementary parameters passed through the parameters.json file and `simulator_extra_parameters` key\n",
    "        \n",
    "        \"\"\"        \n",
    "    def __init__(self,\n",
    "                 benchmark,\n",
    "                 config,\n",
    "                 device, \n",
    "                 **kwargs):\n",
    "        ## You can use this function to infer the inputs and outputs size or giving directly the sizes\n",
    "        input_size, output_size = infer_input_output_size(benchmark.train_dataset)\n",
    "\n",
    "        self.params = config.get_options_dict() #Â Load parameters from config.ini file\n",
    "        ## Paramaters can be passsed through \"simulator_extra_parameters\" in the parameters.json file\n",
    "        self.params.update(kwargs) # update parameters with user defined `simulator_extra_parameters` parameters\n",
    "        name = self.params[\"name\"]\n",
    "        hidden_sizes = self.params[\"layers\"]     \n",
    "\n",
    "        # initialisation of the model\n",
    "        model = MyCustomModel(name=name,\n",
    "                              input_size=input_size,\n",
    "                              output_size=output_size,\n",
    "                              hidden_sizes=hidden_sizes,\n",
    "                              activation=F.relu\n",
    "                             )\n",
    "\n",
    "\n",
    "        super().__init__(model)\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "\n",
    "    def build_model(self):\n",
    "        self.model.build_model()\n",
    "\n",
    "    def train(self, train_dataset, val_dataset, **kwargs):\n",
    "        ## training and validation set are passed during training\n",
    "        train_loader = process_dataset(train_dataset, training=True)\n",
    "        val_loader = process_dataset(val_dataset)\n",
    "\n",
    "        ##training parameters are passed through parameters.json\n",
    "        params = kwargs\n",
    "        self.build_model()\n",
    "        self.model.to(self.device)\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        # select your optimizer\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=params[\"lr\"])\n",
    "        # select your loss function\n",
    "        loss_function = nn.MSELoss()\n",
    "        for epoch in range(params[\"epochs\"]):\n",
    "            # set your model for training\n",
    "            self.model.train()\n",
    "            total_loss = 0\n",
    "            # iterate over the batches of data\n",
    "            for batch in train_loader:\n",
    "                data, target = batch\n",
    "                # transfer your data on proper device. The model and your data should be on the same device\n",
    "                data = data.to(self.device)\n",
    "                target = target.to(self.device)\n",
    "                # reset the gradient\n",
    "                optimizer.zero_grad()\n",
    "                # predict using your model on the current batch of data\n",
    "                prediction = self.model(data)\n",
    "                # compute the loss between prediction and real target\n",
    "                loss = loss_function(prediction, target)\n",
    "                # compute the gradient (backward pass of back propagation algorithm)\n",
    "                loss.backward()\n",
    "                # update the parameters of your model\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item() * len(data)\n",
    "            # the validation step is optional\n",
    "            if val_loader is not None:\n",
    "                val_loss = self.validate(val_loader)\n",
    "                val_losses.append(val_loss)\n",
    "            mean_loss = total_loss / len(train_loader.dataset)\n",
    "            print(f\"Train Epoch: {epoch}   Avg_Loss: {mean_loss:.5f}\")\n",
    "            train_losses.append(mean_loss)\n",
    "        return train_losses, val_losses\n",
    "\n",
    "    def validate(self, val_loader):\n",
    "        # set the model for evaluation (no update of the parameters)\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        loss_function = nn.MSELoss()\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                data, target = batch\n",
    "                data = data.to(self.device)\n",
    "                target = target.to(self.device)\n",
    "                prediction = self.model(data)\n",
    "                loss = loss_function(prediction, target)\n",
    "                total_loss += loss.item()*len(data)\n",
    "            mean_loss = total_loss / len(val_loader.dataset)\n",
    "            print(f\"Eval:   Avg_Loss: {mean_loss:.5f}\")\n",
    "        return mean_loss\n",
    "\n",
    "    def predict(self, dataset, eval_batch_size=128, shuffle=False, env=None, **kwargs):\n",
    "        # set the model for the evaluation\n",
    "        self.model.eval()\n",
    "        predictions = []\n",
    "        observations = []\n",
    "        test_loader = process_dataset(dataset, batch_size=eval_batch_size, training=False, shuffle=shuffle)\n",
    "        # we dont require the computation of the gradient\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                data, target = batch\n",
    "                data = data.to(self.device)\n",
    "                target = target.to(self.device)\n",
    "                prediction = self.model(data)\n",
    "                \n",
    "                if self.device == torch.device(\"cpu\"):\n",
    "                    predictions.append(prediction.numpy())\n",
    "                    observations.append(target.numpy())\n",
    "                else:\n",
    "                    predictions.append(prediction.cpu().data.numpy())\n",
    "                    observations.append(target.cpu().data.numpy())\n",
    "        # reconstruct the prediction in the proper required shape of target variables\n",
    "        predictions = np.concatenate(predictions)\n",
    "        predictions = dataset.reconstruct_output(predictions)\n",
    "        # Do the same for the real observations\n",
    "        observations = np.concatenate(observations)\n",
    "        observations = dataset.reconstruct_output(observations)\n",
    "\n",
    "        return predictions\n",
    "\n",
    "\n",
    "def process_dataset(dataset, batch_size: int=128, training: bool=False, shuffle: bool=False, dtype=torch.float32):\n",
    "    if training:\n",
    "        batch_size = batch_size\n",
    "        extract_x, extract_y = dataset.extract_data()\n",
    "    else:\n",
    "        batch_size = batch_size\n",
    "        extract_x, extract_y = dataset.extract_data()\n",
    "\n",
    "    torch_dataset = TensorDataset(torch.tensor(extract_x, dtype=dtype), torch.tensor(extract_y, dtype=dtype))\n",
    "    data_loader = DataLoader(torch_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    return data_loader\n",
    "\n",
    "def infer_input_output_size(dataset):\n",
    "    *dim_inputs, output_size = dataset.get_sizes()\n",
    "    input_size = np.sum(dim_inputs)\n",
    "    return input_size, output_size\n",
    "\n",
    "\n",
    "class MyCustomModel(nn.Module):\n",
    "    def __init__(self,\n",
    "                 name: str=\"MyCustomFC\",\n",
    "                 input_size: int=None,\n",
    "                 output_size: int=None,\n",
    "                 hidden_sizes: tuple=(100,100,),\n",
    "                 activation=F.relu\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.name = name\n",
    "        \n",
    "        self.activation = activation\n",
    "        \n",
    "        if (input_size is None) & (output_size is None):\n",
    "            self.input_size, self.output_size = infer_input_output_size()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "\n",
    "    def build_model(self):\n",
    "        # model architecture\n",
    "        self.input_layer = nn.Linear(self.input_size, self.hidden_sizes[0])\n",
    "        self.fc_layers = nn.ModuleList([nn.Linear(in_f, out_f) \\\n",
    "                                        for in_f, out_f in zip(self.hidden_sizes[:-1], self.hidden_sizes[1:])])\n",
    "        self.output_layer = nn.Linear(self.hidden_sizes[-1], self.output_size)\n",
    "\n",
    "    def forward(self, data):\n",
    "        \"\"\"The forward pass of the model\n",
    "        \"\"\"\n",
    "        out = self.input_layer(data)\n",
    "        for _, fc_ in enumerate(self.fc_layers):\n",
    "            out = fc_(out)\n",
    "            out = self.activation(out)\n",
    "        out = self.output_layer(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4 : load trained model\n",
    "\n",
    "This example is available in `submission_examples/evaluate_only`\n",
    "\n",
    "**NB** : This type of submission is only for informative purpose, in order for a submission to be valid for the final ranking it needs to be trained and evaluated by the compute node.\n",
    "\n",
    "We offer the possibility to load a trained model in order to evaluate and score it on the compute node. This can be useful to test the submission while limiting the use of compute power on the competition part.\n",
    "\n",
    "In this example we use the same custom model as the previous example.It recreates the 3b notebook with a pre-trained model.\n",
    "This submission is composed of 2 files and a folder containing the pre-trained model :\n",
    "- parameters.json\n",
    "- my_augmented_simulator.py\n",
    "- trained_model/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parameters.json\n",
    "\n",
    "As we are using the same model as example 3 we only need to change the evaluateonly parameter :\n",
    "- `evaluateonly: true`\n",
    "- `scoringonly\": false`\n",
    "\n",
    "The rest of the parameters stay the same and correspond to the parameters needed for the model being loaded:\n",
    "#### simulator_config :\n",
    "As we are use a custom simulator we use :\n",
    "- `simulator_type : \"simple_torch\"`\n",
    "- `simulator_file : \"my_augmented_simulator\"`\n",
    "Which indicate to the compute node that it will need to load the model from `my_augmented_simulator.py`\n",
    "\n",
    "We name the model (used for saving an retrieving models, not important in this type of submission):\n",
    "- `name: \"torch_fc\"`\n",
    "And indicates to the compute node which model we are using :\n",
    "- `model: \"TorchFullyConnected\"`\n",
    "This correspond to the name of the architecture available in LIPS framwork.\n",
    "\n",
    "In this type of submission all data treatment including scalers need to be implemented in the model, we therefore use :\n",
    "- `scaler_type`: \"None\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting `parameters.json` file :\n",
    "```json\n",
    "{\n",
    "  \"evaluateonly\": true,\n",
    "  \"scoringonly\": false,\n",
    "  \"simulator_config\": {\n",
    "    \"simulator_type\": \"simple_torch\",\n",
    "    \"name\": \"torch_fc\",\n",
    "    \"model_type\": \"fully_connected\",\n",
    "    \"model\": \"TorchFullyConnected\",\n",
    "    \"scaler_type\": \"simple\",\n",
    "    \"scaler_module\": \"scaler\",\n",
    "    \"scaler\": \"StandardScaler\",\n",
    "    \"config_name\": \"DEFAULT\",\n",
    "    \"seed\": 42\n",
    "  },\n",
    "  \"simulator_extra_parameters\": {},\n",
    "  \"training_config\": {\n",
    "    \"epochs\": 1\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to be saved and loaded the simulator need to also implement the following function which is called while running the ingestion :\n",
    "- restore(self, path:str) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following functions are added to the simulator class in order to load the model and the scaler:\n",
    "def restore(self, path):\n",
    "    self.load_model(path_model=os.path.join(path, 'SaveFCModel.pt'), path_scaler=os.path.join(path, 'SaveScaler'))\n",
    "\n",
    "def save_model(self, path_model:str,path_scaler:str):\n",
    "    modelWeight=self.model.state_dict()\n",
    "    torch.save(modelWeight,path_model)\n",
    "    self.scaler.save(path_scaler)\n",
    "\n",
    "def load_model(self, path_model:str,path_scaler:str):\n",
    "    model_loader=torch.load(path_model)\n",
    "    self.model.load_state_dict(model_loader)\n",
    "    self.model = self.model.to(self.device)\n",
    "    self.scaler.load(path_scaler)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
