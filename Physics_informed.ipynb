{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Physics Informed Neural Networks\n",
    "\n",
    "This notebook provides a set of utilities allowing to compute the power flow under the physics informed graph neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "To be able to use this notebook and the corresponding functions, you should install the `torch-geometric` package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from lips.benchmark.powergridBenchmark import PowerGridBenchmark\n",
    "from utils.graph_utils import prepare_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use some required pathes\n",
    "import pathlib\n",
    "DATA_PATH = pathlib.Path().resolve() / \"input_data_local\" / \"lips_case14_sandbox\"\n",
    "BENCH_CONFIG_PATH = pathlib.Path().resolve() / \"configs\" / \"benchmarks\" / \"lips_case14_sandbox.ini\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the dataset, if it has not been already done. The dataset used for the purpose of this notebook is generated using DC approximation solver and is only for illustration purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commands required for downloading the DC dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the benchmark. Here, we select a benchmark (`Benchmark_DC`) where the data are generated using DC (Direct Current) approximation solver. It is only for illustration purpose and the participants should use the competition benchmark and dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = PowerGridBenchmark(benchmark_name=\"Benchmark_DC\",\n",
    "                               benchmark_path=DATA_PATH,\n",
    "                               load_data_set=True,\n",
    "                               log_path=None,\n",
    "                               config_path=BENCH_CONFIG_PATH,\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the dataset sizes\n",
    "print(benchmark.train_dataset.size)\n",
    "print(benchmark.val_dataset.size)\n",
    "print(benchmark._test_dataset.size)\n",
    "print(benchmark._test_ood_topo_dataset.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the dataset\n",
    "\n",
    "In order to use a Physics Informed Graph Neural Network, the dataset should be prepared and structured correctly. We provide a set of functions in `utils/graph_utils.py` which help to structure the data as graph and to create corresponding data loaders. This is based on pytorch geometric dependence which should be installed to be able to use the following commands. \n",
    "\n",
    "To install pytorch geometric library, you could use following command.\n",
    "```command\n",
    "! pip install torch-geometric\n",
    "```\n",
    "\n",
    "By calling the `prepare_dataset` function, a set of functions will be called automatically to create the final data loaders for each of `train`, `validation`, `test` and `test_ood` datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "train_loader, val_loader, test_loader, test_ood_loader = prepare_dataset(benchmark=benchmark, batch_size=512, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets have a closer look at a batch of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see here, a batch is composed of following elements (some of the elements could not be used by the model):\n",
    "\n",
    "- ``x`` : is the set of features at the nodes of the graph (`prod_p` and `load_p` in this specific case);\n",
    "- ``edge_index`` : is the pytorch geometric way to create the connections among nodes (works as an adjacency matrix).;\n",
    "- ``edge_attributes`` : the attributes on each edge connecting a pair of nodes (admittance values);\n",
    "- ``y`` : corresponds to the targets at each node of the graph which should be predicted by the model (in this case the target is only the voltage angles from which the active powers could be inferred);\n",
    "- ``edge_index_no_diag`` : is same as edge_index by removing the diagonal elements.\n",
    "- ``edge_attr_no_diag`` : is same as edge_attr by removing the diagonal elements.\n",
    "- ``ybus`` : is the admittance matrix in its classic form.\n",
    "- ``batch`` and ``ptr`` are pytorch geometric specific parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a physics informed GNN\n",
    "This GNN is not trainable. Each layer can be seen as one step optimization of power flow equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils.graph_utils import GPGmodel_without_NN\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "gpg_model_wo_nn = GPGmodel_without_NN(num_gnn_layers=100, device=device)\n",
    "gpg_model_wo_nn.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, this architecture is composed of different layers:\n",
    "- `GPGinput_without_NN`: The input layer of Physics informed GNN\n",
    "- `LocalConservationLayer`:  The layer that computes the local conservation error after each layer.\n",
    "- `GPGintermediate`: The intermediate layer of GNN that updates the theta values with respect ot \n",
    "\n",
    "#### Input layer\n",
    "It performs the computation through the local conservation equation at a node i\n",
    "$P^i_{prod} - P^i_{load} = \\sum_{j \\in \\{i, N(i)\\}} \\theta_j \\times y_{ij}$\n",
    "where:\n",
    "- $P^i_{prod}$: Active power generated at the node $i$\n",
    "- $P^i_{load}$: Active power consumed at the node $i$\n",
    "- $N(i)$ : the neighborhood at node $i$\n",
    "- $\\theta_j$: the voltage angle at node $j$\n",
    "- $y_{ij}$: the admittance matrix element (power line) between node i and j \n",
    "    \n",
    "From this equation, we can update the theta values as follows:\n",
    "$\\hat{\\theta}_i = \\frac{P^i_{prod} - P^i_{load} - \\sum_{j \\in N(i), i\\neq j} \\theta_j \\times y_{ij}}{y_{ii}}$\n",
    "\n",
    "The $\\theta_j$ for this first layer is initialized with zeros.\n",
    "\n",
    "#### Intermediate layer\n",
    "Once the $\\hat{\\theta}_i$ is estimated for all the nodes in power grid, we pass it as an argument to the intermediate layer. This layer performs exactly the same operation as input layer by replacing the $\\theta$ with current estimations in previous layer.\n",
    "\n",
    "#### Local conservation layer\n",
    "It computes the local conservation error after each layer in the Physics Informed GNN to trace the error as:\n",
    "\n",
    "$Error = P^i_{prod} - P^i_{load} - \\sum_{j \\in \\{i, N(i)\\}} \\theta_j \\times y_{ij}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "predictions = []\n",
    "observations = []\n",
    "error_per_batch = []\n",
    "for batch in test_loader:\n",
    "    out, errors = gpg_model_wo_nn(batch)\n",
    "    predictions.append(out)\n",
    "    observations.append(batch.y)\n",
    "    error_per_batch.append([float(error.detach().cpu().numpy()) for error in errors])\n",
    "observations = torch.vstack(observations)\n",
    "predictions = torch.vstack(predictions)\n",
    "errors = np.vstack(error_per_batch)\n",
    "errors = errors.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the error through the iterations (graph layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(errors)\n",
    "plt.xlabel(\"# GNN layers (iterations)\")\n",
    "plt.ylabel(\"Local Conservation Error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the angles from Radian to Degree ($\\times \\frac{180}{\\pi}$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "predictions = predictions * (180/math.pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the MAPE metric on voltage angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAPE = abs((observations - (predictions)) / (observations + 1e-10)).mean()\n",
    "print(\"MAPE: \", MAPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute MAPE10 on voltage angles (90% highest quantile of the distribution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lips.metrics.ml_metrics.external_metrics import mape_quantile\n",
    "\n",
    "MAPE_10 = mape_quantile(y_true=observations.detach().cpu(), y_pred=predictions.detach().cpu(), quantile=0.9)\n",
    "print(\"MAPE 10: \", MAPE_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the voltage angles are computed using the model, we can transform them to power flows (active powers) using the provided function `get_all_active_powers`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from utils.graph_utils import get_obs, get_all_active_powers\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "env, obs = get_obs(benchmark)\n",
    "p_ors_pred, p_exs_pred = get_all_active_powers(benchmark._test_dataset.data,\n",
    "                                               obs,\n",
    "                                               theta_bus=predictions.view(-1,14).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_predictions = {}\n",
    "my_predictions[\"p_or\"] = p_ors_pred\n",
    "my_predictions[\"p_ex\"] = p_exs_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAPE10_Power = mape_quantile(y_true=benchmark._test_dataset.data[\"p_or\"], \n",
    "                             y_pred=my_predictions[\"p_or\"], \n",
    "                             quantile=0.9)\n",
    "print(\"MAPE10 on Active Powers: \", MAPE10_Power)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Physics law verification \n",
    "\n",
    "Once the power flow is computed from the predicted voltage angles, we can verify the local conservation law using the provided function in LIPS framework. This law is one among 8 physics laws that should be respected in this challenge. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lips.metrics.power_grid.local_conservation import local_conservation\n",
    "\n",
    "LC_tolerance = 1e-2\n",
    "\n",
    "verification = local_conservation(predictions=my_predictions,\n",
    "                                  observations=benchmark._test_dataset.data,\n",
    "                                  tolerance=LC_tolerance,\n",
    "                                  env=env,\n",
    "                                  result_level=2)\n",
    "print(f\"Violation percentage: {verification['violation_percentage']:.2f} %\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lips",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
