{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use some required pathes\n",
    "import pathlib\n",
    "DATA_PATH = pathlib.Path().resolve() / \"input_data_local\" / \"lips_idf_2023\"\n",
    "BENCH_CONFIG_PATH = pathlib.Path().resolve() / \"configs\" / \"benchmarks\" / \"lips_idf_2023.ini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../Github/ml4physim_startingkit_powergrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BENCH_CONFIG_PATH.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the required benchmark datasets\n",
    "from lips.benchmark.powergridBenchmark import PowerGridBenchmark\n",
    "\n",
    "benchmark_kwargs = {\"attr_x\": (\"prod_p\", \"prod_v\", \"load_p\", \"load_q\"),\n",
    "                    \"attr_y\": (\"a_or\", \"a_ex\", \"p_or\", \"p_ex\", \"v_or\", \"v_ex\"),\n",
    "                    \"attr_tau\": (\"line_status\", \"topo_vect\"),\n",
    "                    \"attr_physics\": None}\n",
    "\n",
    "benchmark = PowerGridBenchmark(benchmark_name=\"Benchmark_competition\",\n",
    "                               benchmark_path=DATA_PATH,\n",
    "                               load_data_set=True,\n",
    "                               log_path=None,\n",
    "                               config_path=BENCH_CONFIG_PATH,\n",
    "                               **benchmark_kwargs\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300000\n"
     ]
    }
   ],
   "source": [
    "print(len(benchmark.train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the next few lines are specific for each benchmark and each `AugmentedSimulator`\n",
    "import grid2op\n",
    "import warnings\n",
    "from lightsim2grid.lightSimBackend import LightSimBackend\n",
    "from lips.physical_simulator.dcApproximationAS import DCApproximationAS\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    env = grid2op.make(benchmark.config.get_option(\"env_name\"), test=True)\n",
    "    grid_path = pathlib.Path(env.get_path_env()) / \"grid.json\"\n",
    "\n",
    "\n",
    "\n",
    "dc_sim = DCApproximationAS(name=\"dc_approximation\", \n",
    "                           benchmark_name=\"Benchmark_competition\",\n",
    "                           config_path=BENCH_CONFIG_PATH,\n",
    "                           grid_path=grid_path,\n",
    "                        #    backend=LightSimBackend,\n",
    "                           ignore_assert=True\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluate dc:   0%|‚ñè                                                                        | 264/100000 [00:24<2:32:50, 10.88it/s]"
     ]
    }
   ],
   "source": [
    "EVALUATION_PATH = os.path.join(\"input_data_local\", \"eval_results\", \"lips_idf_2023\", \"dc_approximation\")\n",
    "dc_metrics_per_dataset = benchmark.evaluate_simulator(augmented_simulator=dc_sim,\n",
    "                                                       dataset=\"all\", # other values : \"val\", \"test\", \"test_ood_topo\"\n",
    "                                                       save_path=EVALUATION_PATH,\n",
    "                                                       save_predictions=True\n",
    "                                                      )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
